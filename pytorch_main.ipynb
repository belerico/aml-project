{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/ef/54b8da26f37787f5c670ae2199329e7dccf195c060b25628d99e587dac51/torchtext-0.5.0-py3-none-any.whl (73kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 378kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (from torchtext) (4.41.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (from torchtext) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: torch in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (from torchtext) (1.4.0+cpu)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/e0/1264990c559fb945cfb6664742001608e1ed8359eeec6722830ae085062b/sentencepiece-0.1.85-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 1.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (from torchtext) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: requests in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (from torchtext) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (from requests->torchtext) (1.25.7)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (from requests->torchtext) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (from requests->torchtext) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (from requests->torchtext) (3.0.4)\n",
      "Installing collected packages: sentencepiece, torchtext\n",
      "Successfully installed sentencepiece-0.1.85 torchtext-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (4.41.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[39m\u001b[22mShell for\u001b[39m\u001b[22m \u001b[32m\u001b[1m/home/belerico/.local/share/virtualenvs/aml-project-EQl709OG\u001b[39m\u001b[22m \u001b[39m\u001b[1malready activated.\u001b[39m\u001b[22m\r\n",
      "No action taken to avoid nested environments.\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pipenv shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stopwords = set(stopwords.words(\"english\"))\n",
    "non_alphanum_regex = re.compile(r'\\W+')\n",
    "\n",
    "def preprocess(doc, method='nltk', dataset=True):\n",
    "    if method == 'spacy':\n",
    "        tokens = \" \".join(\n",
    "            [\n",
    "                token.lower_\n",
    "                for token in doc\n",
    "                if token\n",
    "                and not (token.lower_ == \"null\" or token.is_stop or token.is_punct)\n",
    "            ]\n",
    "        )\n",
    "    elif method == 'nltk':\n",
    "        # doc = non_alphanum_regex.sub(' ', doc).lower()\n",
    "        tokens = [\n",
    "                token\n",
    "                for token in word_tokenize(doc.lower())\n",
    "                if not (token == \"null\" or token in english_stopwords or token in string.punctuation)\n",
    "            ]\n",
    "    elif method == 'keras':\n",
    "        tokens = \" \".join(\n",
    "            [\n",
    "                token\n",
    "                for token in text_to_word_sequence(doc)\n",
    "                if not (token == \"null\" or token in english_stopwords or token in string.punctuation)\n",
    "            ]\n",
    "        )\n",
    "    if dataset or tokens != \"\":\n",
    "        return tokens\n",
    "\n",
    "\n",
    "def parse_content_line(x, attributes=None, label=True):\n",
    "    if attributes is None:\n",
    "        attributes = [\"title_left\", \"title_right\"]\n",
    "    item = json.loads(x)\n",
    "    elements = [item[attr] if item[attr] is not None else '' for attr in attributes]\n",
    "    if label:\n",
    "        elements.append(int(item[\"label\"]))\n",
    "    item = np.array(elements)\n",
    "    return item[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Field\n",
    "\n",
    "TEXT = Field(sequential=True, tokenize=preprocess, lower=True, fix_length=20, batch_first=True)\n",
    "LABEL = Field(sequential=False, use_vocab=False, is_target=True, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import pandas\n",
    "\n",
    "contents = []\n",
    "for i, x in enumerate(open('./dataset/computers/train/computers_splitted_train_medium.json', \"r\").readlines()):\n",
    "    try:\n",
    "        item = parse_content_line(x, attributes=None, label=True)\n",
    "        contents.append(item)\n",
    "    except:\n",
    "        print(\"Lost data at line {}\".format(i))\n",
    "\n",
    "contents = np.concatenate(contents, axis=0)\n",
    "train = pandas.DataFrame(data=contents, columns=['title_left', 'title_right', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import pandas\n",
    "\n",
    "contents = []\n",
    "for i, x in enumerate(open('./dataset/computers/valid/computers_splitted_valid_medium.json', \"r\").readlines()):\n",
    "    try:\n",
    "        item = parse_content_line(x, attributes=None, label=True)\n",
    "        contents.append(item)\n",
    "    except:\n",
    "        print(\"Lost data at line {}\".format(i))\n",
    "\n",
    "contents = np.concatenate(contents, axis=0)\n",
    "valid = pandas.DataFrame(data=contents, columns=['title_left', 'title_right', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import pandas\n",
    "\n",
    "contents = []\n",
    "for i, x in enumerate(open('./dataset/computers/test/computers_gs.json', \"r\").readlines()):\n",
    "    try:\n",
    "        item = parse_content_line(x, attributes=None, label=True)\n",
    "        contents.append(item)\n",
    "    except:\n",
    "        print(\"Lost data at line {}\".format(i))\n",
    "\n",
    "contents = np.concatenate(contents, axis=0)\n",
    "test = pandas.DataFrame(data=contents, columns=['title_left', 'title_right', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Field, Dataset, Example\n",
    "import pandas as pd\n",
    "\n",
    "class DataFrameDataset(Dataset):\n",
    "    \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n",
    "    def __init__(self, examples, fields, filter_pred=None):\n",
    "        \"\"\"\n",
    "        Create a dataset from a pandas dataframe of examples and Fields\n",
    "        Arguments:\n",
    "            examples pd.DataFrame: DataFrame of examples\n",
    "            fields {str: Field}: The Fields to use in this tuple. The\n",
    "                string is a field name, and the Field is the associated field.\n",
    "            filter_pred (callable or None): use only exanples for which\n",
    "                filter_pred(example) is true, or use all examples if None.\n",
    "                Default is None\n",
    "        \"\"\"\n",
    "        self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n",
    "        if filter_pred is not None:\n",
    "            self.examples = filter(filter_pred, self.examples)\n",
    "        self.fields = dict(fields)\n",
    "        # Unpack field tuples\n",
    "        for n, f in list(self.fields.items()):\n",
    "            if isinstance(n, tuple):\n",
    "                self.fields.update(zip(n, f))\n",
    "                del self.fields[n]\n",
    "        \n",
    "                \n",
    "class SeriesExample(Example):\n",
    "    \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
    "    @classmethod\n",
    "    def fromSeries(cls, data, fields):\n",
    "        return cls.fromdict(data.to_dict(), fields)\n",
    "    \n",
    "    @classmethod\n",
    "    def fromdict(cls, data, fields):\n",
    "        ex = cls()\n",
    "        for key, field in fields.items():\n",
    "            if key not in data:\n",
    "                raise ValueError(\"Specified key {} was not found in \"\n",
    "                \"the input data\".format(key))\n",
    "            if field is not None:\n",
    "                setattr(ex, key, field.preprocess(data[key]))\n",
    "            else:\n",
    "                setattr(ex, key, data[key])\n",
    "        return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fields = {\"title_left\": TEXT, 'title_right': TEXT, 'label': LABEL}\n",
    "train_ds = DataFrameDataset(train, fields)\n",
    "valid_ds = DataFrameDataset(valid, fields)\n",
    "test_ds = DataFrameDataset(test, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asus', 'prime', 'x299', 'deluxe', 'prijzen', 'tweakers']\n",
      "['495906', 'b21', 'hp', 'x5560', '2', '80ghz', 'ml350', 'g6', 'new', 'wholesale', 'price']\n",
      "['417772', 'b21', 'hp', 'xeon', '5130', '2', '0ghz', 'dl140', 'g3', 'new', 'wholesale', 'price']\n"
     ]
    }
   ],
   "source": [
    "print(train_ds[0].title_left)\n",
    "print(valid_ds[0].title_left)\n",
    "print(test_ds[0].title_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_ds, valid_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torchtext.vocab import Vectors\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./dataset/embeddings/w2v/w2v_title_300Epochs_1MinCount_9ContextWindow_150d.bin', binary=True)\n",
    "# needed vectors not in binary form\n",
    "# vectors = Vectors(name='new_w2v_title_300Epochs_1MinCount_9ContextWindow_150d.bin', cache='./dataset/embeddings/w2v') # model_name + path = path_to_embeddings_file\n",
    "TEXT.vocab.set_vectors(vectors.stoi, vectors.vectors, vectors.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator, BucketIterator\n",
    "\n",
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "     (train_ds, valid_ds, test_ds), # we pass in the datasets we want the iterator to draw data from\n",
    "     batch_sizes=(32, 64, 64),\n",
    "     device=torch.device('cpu'), # if you want to use the GPU, specify the GPU number here\n",
    "     sort_key=lambda x: min(max(len(x.title_left), len(x.title_right)), 20), # the BucketIterator needs to be told what function it should use to group the data.\n",
    "     sort_within_batch=True,\n",
    "     shuffle=True,\n",
    "     repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x_vars, y_var):\n",
    "        self.dl, self.x_vars, self.y_var = dl, x_vars, y_var # we pass in the list of attributes for x \n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            left = getattr(batch, self.x_vars[0]) # we assume only one input in this wrapper\n",
    "            right = getattr(batch, self.x_vars[1]) # we assume only one input in this wrapper\n",
    "            y = torch.Tensor(list(map(float, getattr(batch, self.y_var))))\n",
    "\n",
    "            yield (left, right, y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "train_dl = BatchWrapper(train_iter, ['title_left', 'title_right'], 'label')\n",
    "valid_dl = BatchWrapper(val_iter, ['title_left', 'title_right'], 'label')\n",
    "test_dl = BatchWrapper(test_iter, ['title_left', 'title_right'], 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   2, 1610,    7, 1199,  825,    5, 2600, 2593,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [1296,    7,    2,  104,  806,  143,  175,   86,   38,   14,   10,    9,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [ 441,  115,  313,  759,  120,   66,   26,  279,   53,  132,  169,  238,\n",
       "           239,  240,  230,    1,    1,    1,    1,    1],\n",
       "         [1556,  428,   12,   11,   41, 1157,    4,  205,   56,  185,  355,  304,\n",
       "            31,   96, 2516,   84,    1,    1,    1,    1],\n",
       "         [1415,    7,    2,   65, 1951,  140,  444,  412,   14,    3,   51,   10,\n",
       "             9,  183,    1,    1,    1,    1,    1,    1],\n",
       "         [   2,  104,  140,  444,  161, 1140,  859,   99,  399,  989, 1196, 1222,\n",
       "            22,   38,  188,  262,    1,    1,    1,    1],\n",
       "         [1299,  408,    2,  202,    5,  190,   67,    3,    6,  120,   81,   14,\n",
       "            51,   10,    9,  223,    1,    1,    1,    1],\n",
       "         [1556,  428,   12,   11,   27,  610,    4,  166,   56,  185,  355,  304,\n",
       "            31,   96, 2312,   84,    1,    1,    1,    1],\n",
       "         [1100,   95,   28,  129,   52,  102,    4,    6,  110,  359,   15,   14,\n",
       "            10,    9,    1,    1,    1,    1,    1,    1],\n",
       "         [  20,   85,   29,  116,   50,    3,  149,   11,   27,  452,  250,  322,\n",
       "          1277,  583,  170, 1460,    1,    1,    1,    1],\n",
       "         [  12,   11,   41,  764,    4,    6,  122,   31,   73,  243,  162,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  13,   46,   29, 1982,   34,   30,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [1114,  408,    2,  202,    5,  135,    4,    6,  359,   81,   42,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  13,   45,   33,   46,  107,  372,   22,   38,  260, 3018, 2231,   25,\n",
       "            18,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  35,   54,  524,  190,   34,   30,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [1522, 1501,   19,   80,   34,   30,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  39,  146,    4, 1146,   82,   11,  336,  229,   31,  552,  714,  403,\n",
       "          3260, 1605,   25,   18,    1,    1,    1,    1],\n",
       "         [  47,  123, 2672,  160,   98,   44,    4,   37,  193,   60,   16, 3248,\n",
       "           813,   25,   18,    1,    1,    1,    1,    1],\n",
       "         [1152,    7,    2,  202,    5,  135,    4,    6,  359,   81,   14,   48,\n",
       "            51,   10,    9,  244,    1,    1,    1,    1],\n",
       "         [1715, 1729, 1730,    2,  163,   43,    5,  295,  164,  135,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [ 100,  413,   36,  258,   29,   15,  509,  777, 1447,   57,   59,   16,\n",
       "           201, 1827, 3755,   17,    1,    1,    1,    1],\n",
       "         [ 141,    8,   54,  180,  903,   44,    4,   37,  148, 1430, 1137,  215,\n",
       "           255,  470,   21, 1935,    1,    1,    1,    1],\n",
       "         [ 100,  516,   29,  220,    3,  495,  203,   57,   59,   16,   36,  201,\n",
       "          1602, 3033,   25,   18,    1,    1,    1,    1],\n",
       "         [  47,  136, 2005,   36,    3, 2196, 1058,   30,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [1298,  310,    2,  163,    5,  135,    4,    6,  120,   81,   42,   14,\n",
       "            10,    9,    1,    1,    1,    1,    1,    1],\n",
       "         [  39,  146,    6,  775,  217,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [1417,    7,    2,  176,  211,  587,    5,  110,    3,    6,   81,  253,\n",
       "            36,   10,    9,    1,    1,    1,    1,    1],\n",
       "         [1474,    7,    2,  535,    5,   28,  651,   52,  102,    4,    6,   15,\n",
       "            42, 1045,  337,  347,    1,    1,    1,    1],\n",
       "         [1255,  408,    2,  176,  211,  433,    5,  110,    3,    6,   81, 1188,\n",
       "            36,   14,   10,    9,    1,    1,    1,    1],\n",
       "         [  92,  438,  353,   15,   75,    3,  850,   97,   57,   59,   16,  169,\n",
       "           238,  239,  240,  230,    1,    1,    1,    1],\n",
       "         [1952,   49, 1283, 2204,  318,  117, 1649,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [1418,    7,    2,  176,  211,  587,    5,  190,    4,    6,   15,  674,\n",
       "            36,   14,   10,    9,    1,    1,    1,    1]]),\n",
       " tensor([[1417,    7,    2,  176,  211,  587,    5,  110,    3,    6,   81,  253,\n",
       "            36,   14,   10,    9,    1,    1,    1,    1],\n",
       "         [ 446,  447,  248,   65,  143,  175,  393,  857, 1553,   22,  195,  533,\n",
       "           268,  531,  792,    7,    1,    1,    1,    1],\n",
       "         [ 928,  184,  988,  137, 1216,   66,   26,   32,    5, 3094, 1144, 2378,\n",
       "           180,  284,  103,    8,    1,    1,    1,    1],\n",
       "         [  12,   11,   41,  779,   82,   32,    4,  487,  122,   31,   56, 2801,\n",
       "           724, 3948,   51,    1,    1,    1,    1,    1],\n",
       "         [ 354,  112,  233, 1055,   65,  723,  193,  266,  679,   15,   75, 2115,\n",
       "             7,  617,   24,    8,    1,    1,    1,    1],\n",
       "         [ 830,    7,    2,  104,  678,  927,  161,   38,   14,   10,    9,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [1043,    2,  163,    5,  190,  135,    3,    6,  120,   81,   42,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  12,   11,   27,  610,    4,  166,   82,   31, 2312,   76,  308,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [2263,    2,  535,    5,   52,  102,    4,    6,  483,   15,   14,    3,\n",
       "            51,   10,    9,  183,    1,    1,    1,    1],\n",
       "         [  20,  145,  314,   50,    4,  178,   82,   11,   27,  250,  322,  925,\n",
       "           142,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  12,   11,   41,  764,  682,   82, 2543,   31, 1050,    4,  149, 1763,\n",
       "          1736,  476,   96,  209,    1,    1,    1,    1],\n",
       "         [  13,   46,  107,  139,   45,  657,   33,  106,  643,  513,   54,   82,\n",
       "           111,   38, 1008,   84,    1,    1,    1,    1],\n",
       "         [1114,  408,    2,  202,    5,  135,    4,    6,  359,   81,   14,   48,\n",
       "            51,   10,    9,  244,    1,    1,    1,    1],\n",
       "         [  13,   46,  107,   21,   45,  657,   33,  106,  430,  316,   54,  111,\n",
       "            38,  260, 1738,   84,    1,    1,    1,    1],\n",
       "         [ 449,  115,   72,   71,  875,  348,   53,  231,   66,   26, 3245,  873,\n",
       "          3279, 3093,   25,   18,    1,    1,    1,    1],\n",
       "         [   4,    6,  575,  349, 3654,  411, 2376, 3679,  697,  794,  130,   15,\n",
       "            75,  661,  274,  675,    1,    1,    1,    1],\n",
       "         [  39,  146,   52,  937,    4,  168,   43,   11,   31, 1026,   76,  491,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  47,  457,  160,  214,   98,  123,   44,    4,   37,   28,  523,  490,\n",
       "            21,   60,   16,  813,    1,    1,    1,    1],\n",
       "         [1152,    7,    2,  202,    5,  135,    4,    6,  359,   81,   14,   51,\n",
       "            10,    9,  223,    1,    1,    1,    1,    1],\n",
       "         [1715, 1729, 1730,    2,  163,   43,    5,  295,  164,  135,   14,   48,\n",
       "            51,   10,    9,  244,    1,    1,    1,    1],\n",
       "         [ 100,  516,   29,  220,    3,  495,  203,   57,   59,   16,   36,  201,\n",
       "          1602, 3033,   25,   18,    1,    1,    1,    1],\n",
       "         [ 141, 1935,  148,  979,  215,  255,  470, 1226,  227, 3010,   25,   18,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  92,  353,  438,    3,  850,  509,   57,   59,   16, 1530,   17,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  92,  353,  167,   36, 1530,   57,   59,   16,  137,    5,   15,   75,\n",
       "            90,  226,   24,    8,    1,    1,    1,    1],\n",
       "         [1298,  310,    2,  163,    5,  135,    4,    6,  120,   81,   14,   48,\n",
       "            51,   10,    9,  244,    1,    1,    1,    1],\n",
       "         [ 342,  573,   12,   11,   27,  854,    4,  632,  983,   56, 1050,   31,\n",
       "          1967,   96, 2549,   17,    1,    1,    1,    1],\n",
       "         [1255,  408,    2,  176,  211,  433,    5,  110,    3,    6,   81, 1188,\n",
       "            36,   14,   10,    9,    1,    1,    1,    1],\n",
       "         [1100,   95,   28,  129,   52,  102,    4,    6,  110,  359,   15,   14,\n",
       "            51,   10,    9,  223,    1,    1,    1,    1],\n",
       "         [1255,  408,    2,  176,  211,  433,    5,  110,    3,    6,   81, 1188,\n",
       "            36,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  92,  353,  438,    3,    6,   15,  509,   57,   59,   16, 1106, 3081,\n",
       "            17,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [ 446,  447,  248,  359, 2956, 1258,  266,  112,  233,  165,  533,  268,\n",
       "          2161,  617, 1952,   49,    1,    1,    1,    1],\n",
       "         [1042,    2,  252,    5,  190,   67,    3,    6,  120,   81,   42,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1]]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "         1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.]))"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class SimpleLSTMBaseline(nn.Module):\n",
    "    def __init__(self, hidden_dim, emb_dim=150):\n",
    "        super().__init__() # don't forget to call this!\n",
    "        # model = gensim.models.KeyedVectors.load_word2vec_format('./dataset/embeddings/w2v/w2v_title_300Epochs_1MinCount_9ContextWindow_150d.bin', binary=True)\n",
    "        # weights = torch.FloatTensor(model.vectors)\n",
    "        self.embedding = nn.Embedding.from_pretrained(TEXT.vocab.vectors)\n",
    "        self.encoder_left = nn.LSTM(emb_dim, hidden_dim, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        self.encoder_right = nn.LSTM(emb_dim, hidden_dim, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(16)\n",
    "        self.max_pool1 = nn.MaxPool2d(2)\n",
    "        self.mlp1 = nn.Linear(1296, 32)\n",
    "        self.mlp2 = nn.Linear(32, 16)\n",
    "        self.out = nn.Linear(16, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, seq):\n",
    "        hdn_left, _ = self.encoder_left(self.embedding(seq[0]))\n",
    "        hdn_right, _ = self.encoder_right(self.embedding(seq[1]))\n",
    "        similarity = torch.matmul(hdn_left, torch.transpose(hdn_right, 1, 2))\n",
    "        similarity = torch.unsqueeze(similarity, 1)\n",
    "        x = self.conv1(similarity)\n",
    "        x = F.relu(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.mlp1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.mlp2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.out(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = SimpleLSTMBaseline(hidden_dim=150, emb_dim=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.5033, Validation Loss: 0.5119, Precision: 0.6124, Recall: 0.7826, F1: 0.6871\n",
      "Epoch: 2, Training Loss: 0.4726, Validation Loss: 0.5129, Precision: 0.6861, Recall: 0.7783, F1: 0.6927\n",
      "Epoch: 3, Training Loss: 0.4235, Validation Loss: 0.5174, Precision: 0.7144, Recall: 0.7665, F1: 0.7246\n",
      "Epoch: 4, Training Loss: 0.3495, Validation Loss: 0.5286, Precision: 0.7404, Recall: 0.7647, F1: 0.7491\n",
      "Epoch: 5, Training Loss: 0.2795, Validation Loss: 0.5612, Precision: 0.7589, Recall: 0.7857, F1: 0.7653\n",
      "Epoch: 6, Training Loss: 0.2189, Validation Loss: 0.5887, Precision: 0.7557, Recall: 0.7739, F1: 0.7626\n",
      "Epoch: 7, Training Loss: 0.1650, Validation Loss: 0.6652, Precision: 0.7733, Recall: 0.7912, F1: 0.7792\n",
      "Epoch: 8, Training Loss: 0.1264, Validation Loss: 0.6948, Precision: 0.7769, Recall: 0.7844, F1: 0.7803\n",
      "Epoch: 9, Training Loss: 0.0948, Validation Loss: 0.7292, Precision: 0.7741, Recall: 0.7764, F1: 0.7752\n",
      "Epoch: 10, Training Loss: 0.0828, Validation Loss: 0.7870, Precision: 0.7779, Recall: 0.7869, F1: 0.7818\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "epochs = 15\n",
    "\n",
    "y_true = [v[2] for v in valid_dl]\n",
    "y_true = functools.reduce(operator.iconcat, y_true, [])\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train() # turn on training mode\n",
    "    for left, right, y in train_dl: # thanks to our wrapper, we can intuitively iterate over our data!\n",
    "        opt.zero_grad()\n",
    "        preds = model([left, right])\n",
    "        loss = loss_func(preds, torch.unsqueeze(y, 1))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running_loss += loss.data.item()\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_dl)\n",
    "\n",
    "    # calculate the validation loss for this epoch\n",
    "    val_loss = 0.0\n",
    "    model.eval() # turn on evaluation mode\n",
    "    predictions = []\n",
    "    for left, right, y in valid_dl:\n",
    "        preds = model([left, right])\n",
    "        predictions.extend(preds.data > .5)\n",
    "        loss = loss_func(preds, torch.unsqueeze(y, 1))\n",
    "        val_loss += loss.data.item()\n",
    "    \n",
    "    results = classification_report(y_true, predictions, digits=4, output_dict=True)\n",
    "    val_loss /= len(valid_dl)\n",
    "    print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1: {:.4f}'.format(epoch, epoch_loss, val_loss, results['weighted avg']['precision'], results['weighted avg']['recall'], results['weighted avg']['f1-score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import operator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = [v[2] for v in test_dl]\n",
    "y_true = functools.reduce(operator.iconcat, y_true, [])\n",
    "predictions = []\n",
    "model.eval() # turn on evaluation mode\n",
    "for left, right, y in test_dl:\n",
    "    preds = model([left, right])\n",
    "    predictions.extend(preds.data > .5)\n",
    "print(classification_report(y_true, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
