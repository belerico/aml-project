{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/ef/54b8da26f37787f5c670ae2199329e7dccf195c060b25628d99e587dac51/torchtext-0.5.0-py3-none-any.whl (73kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 378kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (from torchtext) (4.41.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (from torchtext) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: torch in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (from torchtext) (1.4.0+cpu)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/e0/1264990c559fb945cfb6664742001608e1ed8359eeec6722830ae085062b/sentencepiece-0.1.85-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 1.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (from torchtext) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: requests in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (from torchtext) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (from requests->torchtext) (1.25.7)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (from requests->torchtext) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (from requests->torchtext) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (from requests->torchtext) (3.0.4)\n",
      "Installing collected packages: sentencepiece, torchtext\n",
      "Successfully installed sentencepiece-0.1.85 torchtext-0.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/belerico/.local/share/virtualenvs/aml-project-EQl709OG/lib/python3.7/site-packages (4.41.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[39m\u001b[22mShell for\u001b[39m\u001b[22m \u001b[32m\u001b[1m/home/belerico/.local/share/virtualenvs/aml-project-EQl709OG\u001b[39m\u001b[22m \u001b[39m\u001b[1malready activated.\u001b[39m\u001b[22m\r\n",
      "No action taken to avoid nested environments.\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pipenv shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import torch\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "english_stopwords = set(stopwords.words(\"english\"))\n",
    "non_alphanum_regex = re.compile(r'\\W+')\n",
    "\n",
    "def preprocess(doc, method='nltk', dataset=True):\n",
    "    if method == 'spacy':\n",
    "        tokens = \" \".join(\n",
    "            [\n",
    "                token.lower_\n",
    "                for token in doc\n",
    "                if token\n",
    "                and not (token.lower_ == \"null\" or token.is_stop or token.is_punct)\n",
    "            ]\n",
    "        )\n",
    "    elif method == 'nltk':\n",
    "        # doc = non_alphanum_regex.sub(' ', doc).lower()\n",
    "        tokens = [\n",
    "                token\n",
    "                for token in word_tokenize(doc.lower())\n",
    "                if not (token == \"null\" or token in english_stopwords or token in string.punctuation)\n",
    "            ]\n",
    "    elif method == 'keras':\n",
    "        tokens = \" \".join(\n",
    "            [\n",
    "                token\n",
    "                for token in text_to_word_sequence(doc)\n",
    "                if not (token == \"null\" or token in english_stopwords or token in string.punctuation)\n",
    "            ]\n",
    "        )\n",
    "    if dataset or tokens != \"\":\n",
    "        return tokens\n",
    "\n",
    "\n",
    "def parse_content_line(x, attributes=None, label=True):\n",
    "    if attributes is None:\n",
    "        attributes = [\"title_left\", \"title_right\"]\n",
    "    item = json.loads(x)\n",
    "    elements = [item[attr] if item[attr] is not None else '' for attr in attributes]\n",
    "    if label:\n",
    "        elements.append(int(item[\"label\"]))\n",
    "    item = np.array(elements)\n",
    "    return item[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Field\n",
    "\n",
    "TEXT = Field(sequential=True, tokenize=preprocess, lower=True, fix_length=20, batch_first=True)\n",
    "LABEL = Field(sequential=False, use_vocab=False, is_target=True, batch_first=True, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import pandas\n",
    "\n",
    "contents = []\n",
    "for i, x in enumerate(open('./dataset/computers/train/computers_splitted_train_medium.json', \"r\").readlines()):\n",
    "    try:\n",
    "        item = parse_content_line(x, attributes=None, label=True)\n",
    "        contents.append(item)\n",
    "    except:\n",
    "        print(\"Lost data at line {}\".format(i))\n",
    "\n",
    "contents = np.concatenate(contents, axis=0)\n",
    "train = pandas.DataFrame(data=contents, columns=['title_left', 'title_right', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import pandas\n",
    "\n",
    "contents = []\n",
    "for i, x in enumerate(open('./dataset/computers/valid/computers_splitted_valid_medium.json', \"r\").readlines()):\n",
    "    try:\n",
    "        item = parse_content_line(x, attributes=None, label=True)\n",
    "        contents.append(item)\n",
    "    except:\n",
    "        print(\"Lost data at line {}\".format(i))\n",
    "\n",
    "contents = np.concatenate(contents, axis=0)\n",
    "valid = pandas.DataFrame(data=contents, columns=['title_left', 'title_right', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import pandas\n",
    "\n",
    "contents = []\n",
    "for i, x in enumerate(open('./dataset/computers/test/computers_gs.json', \"r\").readlines()):\n",
    "    try:\n",
    "        item = parse_content_line(x, attributes=None, label=True)\n",
    "        contents.append(item)\n",
    "    except:\n",
    "        print(\"Lost data at line {}\".format(i))\n",
    "\n",
    "contents = np.concatenate(contents, axis=0)\n",
    "test = pandas.DataFrame(data=contents, columns=['title_left', 'title_right', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Field, Dataset, Example\n",
    "import pandas as pd\n",
    "\n",
    "class DataFrameDataset(Dataset):\n",
    "    \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n",
    "    def __init__(self, examples, fields, filter_pred=None):\n",
    "        \"\"\"\n",
    "        Create a dataset from a pandas dataframe of examples and Fields\n",
    "        Arguments:\n",
    "            examples pd.DataFrame: DataFrame of examples\n",
    "            fields {str: Field}: The Fields to use in this tuple. The\n",
    "                string is a field name, and the Field is the associated field.\n",
    "            filter_pred (callable or None): use only exanples for which\n",
    "                filter_pred(example) is true, or use all examples if None.\n",
    "                Default is None\n",
    "        \"\"\"\n",
    "        self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n",
    "        if filter_pred is not None:\n",
    "            self.examples = filter(filter_pred, self.examples)\n",
    "        self.fields = dict(fields)\n",
    "        # Unpack field tuples\n",
    "        for n, f in list(self.fields.items()):\n",
    "            if isinstance(n, tuple):\n",
    "                self.fields.update(zip(n, f))\n",
    "                del self.fields[n]\n",
    "        \n",
    "                \n",
    "class SeriesExample(Example):\n",
    "    \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
    "    @classmethod\n",
    "    def fromSeries(cls, data, fields):\n",
    "        return cls.fromdict(data.to_dict(), fields)\n",
    "    \n",
    "    @classmethod\n",
    "    def fromdict(cls, data, fields):\n",
    "        ex = cls()\n",
    "        for key, field in fields.items():\n",
    "            if key not in data:\n",
    "                raise ValueError(\"Specified key {} was not found in \"\n",
    "                \"the input data\".format(key))\n",
    "            if field is not None:\n",
    "                setattr(ex, key, field.preprocess(data[key]))\n",
    "            else:\n",
    "                setattr(ex, key, data[key])\n",
    "        return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fields = {\"title_left\": TEXT, 'title_right': TEXT, 'label': LABEL}\n",
    "train_ds = DataFrameDataset(train, fields)\n",
    "valid_ds = DataFrameDataset(valid, fields)\n",
    "test_ds = DataFrameDataset(test, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asus', 'prime', 'x299', 'deluxe', 'prijzen', 'tweakers']\n",
      "['495906', 'b21', 'hp', 'x5560', '2', '80ghz', 'ml350', 'g6', 'new', 'wholesale', 'price']\n",
      "['417772', 'b21', 'hp', 'xeon', '5130', '2', '0ghz', 'dl140', 'g3', 'new', 'wholesale', 'price']\n"
     ]
    }
   ],
   "source": [
    "print(train_ds[0].title_left)\n",
    "print(valid_ds[0].title_left)\n",
    "print(test_ds[0].title_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_ds, valid_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from torchtext.vocab import Vectors\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./dataset/embeddings/w2v/w2v_title_300Epochs_1MinCount_9ContextWindow_150d.bin', binary=True)\n",
    "# needed vectors not in binary form\n",
    "vectors = Vectors(name='new_w2v_title_300Epochs_1MinCount_9ContextWindow_150d.bin', cache='./dataset/embeddings/w2v') # model_name + path = path_to_embeddings_file\n",
    "TEXT.vocab.set_vectors(vectors.stoi, vectors.vectors, vectors.dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator, BucketIterator\n",
    "\n",
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "     (train_ds, valid_ds, test_ds), # we pass in the datasets we want the iterator to draw data from\n",
    "     batch_sizes=(32, 64, 64),\n",
    "     device=torch.device('cpu'), # if you want to use the GPU, specify the GPU number here\n",
    "     sort_key=lambda x: min(max(len(x.title_left), len(x.title_right)), 20), # the BucketIterator needs to be told what function it should use to group the data.\n",
    "     sort_within_batch=True,\n",
    "     shuffle=True,\n",
    "     repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x_vars, y_var):\n",
    "        self.dl, self.x_vars, self.y_var = dl, x_vars, y_var # we pass in the list of attributes for x \n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            left = getattr(batch, self.x_vars[0]) # we assume only one input in this wrapper\n",
    "            right = getattr(batch, self.x_vars[1]) # we assume only one input in this wrapper\n",
    "            y = torch.Tensor(list(map(float, getattr(batch, self.y_var))))\n",
    "\n",
    "            yield (left, right, y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "train_dl = BatchWrapper(train_iter, ['title_left', 'title_right'], 'label')\n",
    "valid_dl = BatchWrapper(val_iter, ['title_left', 'title_right'], 'label')\n",
    "test_dl = BatchWrapper(test_iter, ['title_left', 'title_right'], 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  62,  236, 1533,  114,    6,   28,   37,   74,   69,  216,  185,   56,\n",
       "           844,  555,   24,    8,    1,    1,    1,    1],\n",
       "         [  47,   19,  140,  360,  137,   77,   55,   86,   58,   38, 1920, 1899,\n",
       "          1276,   43,    1,    1,    1,    1,    1,    1],\n",
       "         [ 720,  428,   12,   11,   27,  795,    4,  388,   56,  185,  260,   31,\n",
       "            96, 1164,   84,    1,    1,    1,    1,    1],\n",
       "         [ 449,  115,   72,   71,  371,  348, 1701,  545,   83, 2561,  873, 1387,\n",
       "          1339,   25,   18,    1,    1,    1,    1,    1],\n",
       "         [  13,   70,  106, 1110,  237,   77,   33,   86,   58,   38,  860,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  13,   46,  131,   70,  475,   19,  513,   33,  914,   82,  111,   58,\n",
       "           921,  329,  155,    1,    1,    1,    1,    1],\n",
       "         [  53,   55,  245, 1140,  412,  144,    8,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  47,  160,  333,  492,   44,   60,   16,   88,    5,  722,   45,  521,\n",
       "            90,   24,    8,    1,    1,    1,    1,    1],\n",
       "         [ 108, 1592,  595, 3280, 2526,   45,  479,  179,   26,  276, 1652,  335,\n",
       "           181,    3,   96,    1,    1,    1,    1,    1],\n",
       "         [ 100,  516,  159,  198,   36,    3,  495,  203, 1463,    8,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [ 700,   11,   41,  779,  748,    4,  166,  476, 1754,  462,  424,  613,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [1750, 1786, 1785,  214, 2156, 3001, 1328,  119,  910, 2517, 2810,  532,\n",
       "           622,   24,    8,    1,    1,    1,    1,    1],\n",
       "         [1442, 2281,   57,   59,   16,  307,    5,   15,   75, 2579, 2482,   90,\n",
       "           226,   24,    8,    1,    1,    1,    1,    1],\n",
       "         [  13,   70,  106,  430,  237,   77,   33,   86,   58,   38, 1739,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [ 342,  573,   12,   11,  186, 1001,    4,  527,  370,   56,  365,   31,\n",
       "            96,  984,   17,    1,    1,    1,    1,    1],\n",
       "         [  13,   46,  139,  131,   45,  297,   33,  106,  745,  372,   54,  111,\n",
       "            38, 1373,   84,    1,    1,    1,    1,    1],\n",
       "         [  12,   57,   59,   16,  376,  901,   73,  751,    5,   15, 1190,   90,\n",
       "           226,   24,    8,    1,    1,    1,    1,    1],\n",
       "         [ 364, 1922, 1917,  484, 1874, 1805, 1797,  628,   30,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [ 141,    8,    3,   91,   54,  279,   44,  712,  207,  443,  303, 1572,\n",
       "          1102,  993,   24,    1,    1,    1,    1,    1],\n",
       "         [  13,  125,   73,  578,  334,   83,  276,  616,  399,  272,  315,  834,\n",
       "           177,  329,  155,    1,    1,    1,    1,    1],\n",
       "         [1113,  310,    2,  163,    5,  190,  135,    3,    6,  120,   81,   42,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [1042,    2,  252,    5,  190,   67,    3,    6,  120,   81,   14,   51,\n",
       "            10,    9,  223,    1,    1,    1,    1,    1],\n",
       "         [ 450,  823,    2,  163,   43,    5,   67,  138,  156,   42,   14,   10,\n",
       "             9,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  47,  123,  160,  469,  117,   44,    4,   37,   60,   16,  581,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [ 400, 2069,   87,   69,   32,  101, 3122,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [2159, 2855,  123,  203,  495, 2769,  114,   36, 2824, 2164, 2152,  629,\n",
       "            25,   18,    1,    1,    1,    1,    1,    1],\n",
       "         [1647, 1673,  278,   73,  905,  224,  101,   21, 2800, 1441, 3209,   17,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [ 536,   72,   71,  208,  253, 2114,  132,   63,  126,   66,   26,  477,\n",
       "            17,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  13,   46,  107,   21,   45,  297,   33,  106,  430,  316,   54,  111,\n",
       "            38,  837,   84,    1,    1,    1,    1,    1],\n",
       "         [ 756,  755,   20,  145,  314,   50,    3,  330,   82,   11,   27,  189,\n",
       "           486, 2441,  142,    1,    1,    1,    1,    1],\n",
       "         [1300,   49,    2,  433,    5,   67,    4,    6,  120,   81,   48,   51,\n",
       "           347,  244,    1,    1,    1,    1,    1,    1],\n",
       "         [  47,  448,   60,   22,   26,  363,    5,  259,  243,  162,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1]]),\n",
       " tensor([[  62,  236, 1533,  114,    6,   12,  561,   56,  235,   33,   69,  216,\n",
       "            74,  697,   17,    1,    1,    1,    1,    1],\n",
       "         [ 136, 1275,   21,   73,  377,   43,    5,   58,  382,   77, 2148,  152,\n",
       "            22,   80,   24,    8,    1,    1,    1,    1],\n",
       "         [  12,   11,   41,  779,  187,   34,   30,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  35, 1317,  231,  828,  115,   72,   71,  368,  348,   65,  246,  420,\n",
       "           257,    8,    1,    1,    1,    1,    1,    1],\n",
       "         [  13,   46,  131,  139,   70,  439,   33,  106,  643,  513,   54,  111,\n",
       "            38, 1496,   84,    1,    1,    1,    1,    1],\n",
       "         [  13,   46,  107,   21,   70,  439,   33,  106,  745,  372,   54,  111,\n",
       "            38,  709,   84,    1,    1,    1,    1,    1],\n",
       "         [  47,  136, 1275,   21,   73,   19,  394,  377,  488,  344,   28, 2031,\n",
       "          2148,   43,   17,    1,    1,    1,    1,    1],\n",
       "         [ 108,  165,   70,   44,    4,   37,  786,   60,   16, 1098,  874, 1139,\n",
       "          3014,   25,   18,    1,    1,    1,    1,    1],\n",
       "         [3471,   93,  335,  259,  109, 3593,  489, 3474,  285, 3064, 3549,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  28,  351,  268, 2779,   36, 1883, 2314,   37,   12,  203,   26, 2820,\n",
       "          1286,   25,   18,    1,    1,    1,    1,    1],\n",
       "         [ 720,  428,   12,   11,  186,  505,    4,  127,   56,  185,  260,   31,\n",
       "            96, 1650,   84,    1,    1,    1,    1,    1],\n",
       "         [  39,  184,   29, 1062, 1033,   53,   34,   30,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [1442,  673,   97,   57,   59,   90,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  13,   46,   70,  914,   33,  106, 1799,  316,   82,  111,   38,   21,\n",
       "          3165, 2351,   17,    1,    1,    1,    1,    1],\n",
       "         [  12,   11,   41,  855,  187,   34,   30,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  13,   46,  107,   45,   32,   89,   53,   33,  350,   22, 1008,   76,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [ 298,  100,  389,   73,  599,   57,   59,    3,  454,   16,  201, 1038,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  13,   46,  131,  288,   45,  297,   33,  106,  643,  513,   54,  111,\n",
       "            38,  977,   84,    1,    1,    1,    1,    1],\n",
       "         [ 141,    8, 1102,    3,   91,   54,  279,   44,  712,  207,  303,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [  13,  242,  774,  540,   83,    1,    1,    1,    1,    1,    1,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [ 831,   49,    2,  163,    5,  110,  135,    3,    6,  120,   81,   42,\n",
       "            14,   10,    9,    1,    1,    1,    1,    1],\n",
       "         [1011,    2,  202,    5,  110,   67,    3,    6,  120,   81,   42,    1,\n",
       "             1,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [ 450,  823,    2,  163,   43,    5,   67,  138,  156,   14,    6,   51,\n",
       "            10,    9,  223,    1,    1,    1,    1,    1],\n",
       "         [  13,   60,  346,  423,  221,  590,    5,   44,    4,   37,   16,  182,\n",
       "           511,   94,   84,    1,    1,    1,    1,    1],\n",
       "         [  20,   87,   69,   32,  154,  147,  270,  363,    5,   52,   99, 2444,\n",
       "           507,  103,    8,    1,    1,    1,    1,    1],\n",
       "         [  28,  351,  268, 2779,   36, 1883, 2314,   37,   12,  203,   26, 2820,\n",
       "          1286,   25,   18,    1,    1,    1,    1,    1],\n",
       "         [1647, 1673,  905,  385,  224,  167,  114,  101, 3484,   37, 2498, 2499,\n",
       "            99,   25,   18,    1,    1,    1,    1,    1],\n",
       "         [  62,   72,   71,  219,  904,  542,  231,  658,  132,   63,  126,   66,\n",
       "            26,  173,   17,    1,    1,    1,    1,    1],\n",
       "         [  13,   45,  139,   46,  107,   33,  624,   22,   38,  475,   53, 2696,\n",
       "          2666,   25,   18,    1,    1,    1,    1,    1],\n",
       "         [  20,  314,  145,    3,  598,   82,   11,   12,   27,   79,  133,  985,\n",
       "           302,    1,    1,    1,    1,    1,    1,    1],\n",
       "         [ 831,   49,    2,  163,    5,  110,  135,    3,    6,  120,   81,   42,\n",
       "            14,   10,    9,    1,    1,    1,    1,    1],\n",
       "         [  47,  179,  151,    5,  435,   60,   22,   26, 2167,   70,  338,  249,\n",
       "           150,   52,  534,    1,    1,    1,    1,    1]]),\n",
       " tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class SimpleLSTMBaseline(nn.Module):\n",
    "    def __init__(self, hidden_dim, emb_dim=150):\n",
    "        super().__init__() # don't forget to call this!\n",
    "        # model = gensim.models.KeyedVectors.load_word2vec_format('./dataset/embeddings/w2v/w2v_title_300Epochs_1MinCount_9ContextWindow_150d.bin', binary=True)\n",
    "        # weights = torch.FloatTensor(model.vectors)\n",
    "        self.embedding = nn.Embedding.from_pretrained(TEXT.vocab.vectors, padding_idx=TEXT.vocab.stoi[TEXT.pad_token])\n",
    "        self.encoder_left = nn.LSTM(emb_dim, hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.encoder_right = nn.LSTM(emb_dim, hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.conv1 = nn.Conv2d(1, 8, 2)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(8)\n",
    "        self.max_pool1 = nn.MaxPool2d(2)\n",
    "        self.mlp1 = nn.Linear(648, 64)\n",
    "        self.mlp2 = nn.Linear(64, 32)\n",
    "        self.mlp3 = nn.Linear(32, 16)\n",
    "        self.out = nn.Linear(16, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, seq):\n",
    "        output_left, _ = self.encoder_left(self.embedding(seq[0]))\n",
    "        output_right, _ = self.encoder_right(self.embedding(seq[1]))\n",
    "        similarity = torch.matmul(output_left, torch.transpose(output_right, 1, 2))\n",
    "        similarity = torch.unsqueeze(similarity, 1)\n",
    "        x = self.conv1(similarity)\n",
    "        x = F.relu(x)\n",
    "        # x = self.batch_norm1(x)\n",
    "        x = self.max_pool1(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.mlp1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.mlp2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.mlp3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.out(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = SimpleLSTMBaseline(hidden_dim=150, emb_dim=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import functools\n",
    "import operator\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "opt = optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "y_true = [v[2] for v in valid_dl]\n",
    "y_true = functools.reduce(operator.iconcat, y_true, [])\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train() # turn on training mode\n",
    "    for left, right, y in train_dl: # thanks to our wrapper, we can intuitively iterate over our data!\n",
    "        opt.zero_grad()\n",
    "        preds = model([left, right])\n",
    "        loss = loss_func(preds, torch.unsqueeze(y, 1))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running_loss += loss.data.item()\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_dl)\n",
    "\n",
    "    # calculate the validation loss for this epoch\n",
    "    val_loss = 0.0\n",
    "    model.eval() # turn on evaluation mode\n",
    "    predictions = []\n",
    "    for left, right, y in valid_dl:\n",
    "        preds = model([left, right])\n",
    "        predictions.extend(preds.data > .5)\n",
    "        loss = loss_func(preds, torch.unsqueeze(y, 1))\n",
    "        val_loss += loss.data.item()\n",
    "    \n",
    "    results = classification_report(y_true, predictions, digits=4, output_dict=True)\n",
    "    val_loss /= len(valid_dl)\n",
    "    print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1: {:.4f}'.format(epoch, epoch_loss, val_loss, results['weighted avg']['precision'], results['weighted avg']['recall'], results['weighted avg']['f1-score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.90      0.82       800\n",
      "         1.0       0.41      0.19      0.26       300\n",
      "\n",
      "    accuracy                           0.70      1100\n",
      "   macro avg       0.58      0.54      0.54      1100\n",
      "weighted avg       0.66      0.70      0.66      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = [v[2] for v in test_dl]\n",
    "y_true = functools.reduce(operator.iconcat, y_true, [])\n",
    "predictions = []\n",
    "model.eval() # turn on evaluation mode\n",
    "for left, right, y in test_dl:\n",
    "    preds = model([left, right])\n",
    "    predictions.extend(preds.data > .5)\n",
    "print(classification_report(y_true, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
